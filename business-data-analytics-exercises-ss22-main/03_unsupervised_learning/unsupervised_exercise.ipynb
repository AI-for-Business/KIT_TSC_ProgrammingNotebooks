{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Data Analytics - Exercise Unsupervised Learning\n",
    "\n",
    "This notebook demonstrates how **clustering** and **dimensionality reduction** can be applied to segment customers based on their credit card usage behaviour. The code used throughout this tutorial is inspired by [Saba Naseem Butt's notebook on Kaggle](https://www.kaggle.com/code/sabanasimbutt/clustering-visualization-of-clusters-using-pca).\n",
    "\n",
    "The notebook follows these steps:\n",
    "1. Preprocessing \n",
    "2. Clustering\n",
    "3. Interpreting the clusters\n",
    "4. Visualising the results with PCA\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following variables are contained in the dataset:\n",
    "\n",
    "- **CUST_ID**: Identification of Credit Card holder (Categorical)\n",
    "\n",
    "\n",
    "- **BALANCE**: Balance amount left in their account to make purchases\n",
    "\n",
    "\n",
    "- **BALANCE_FREQUENCY**: How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n",
    "\n",
    "\n",
    "- **PURCHASES**: Amount of purchases made from account\n",
    "\n",
    "\n",
    "- **ONEOFF_PURCHASES**: Maximum purchase amount done in one-go\n",
    "\n",
    "\n",
    "- **INSTALLMENTS_PURCHASES**: Amount of purchase done in installment\n",
    "\n",
    "\n",
    "- **CASH_ADVANCE**: Cash in advance given by the user\n",
    "\n",
    "\n",
    "- **PURCHASES_FREQUENCY**: How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n",
    "\n",
    "\n",
    "- **ONEOFF_PURCHASES_FREQUENCY**: How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n",
    "\n",
    "\n",
    "- **PURCHASES_INSTALLMENTS_FREQUENCY**: How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n",
    "\n",
    "\n",
    "- **CASH_ADVANCE_FREQUENCY**: How frequently the cash in advance being paid\n",
    "\n",
    "\n",
    "- **CASH_ADVANCE_TRX**: Number of Transactions made with \"Cash in Advanced\"\n",
    "\n",
    "\n",
    "- **PURCHASES_TRX**: Numbe of purchase transactions made\n",
    "\n",
    "\n",
    "- **CREDIT_LIMIT**: Limit of Credit Card for user\n",
    "\n",
    "\n",
    "- **PAYMENTS**: Amount of Payment done by user\n",
    "\n",
    "\n",
    "- **MINIMUM_PAYMENTS**: Minimum amount of payments made by user\n",
    "\n",
    "\n",
    "- **PRC_FULL_PAYMENT**: Percent of full payment paid by user\n",
    "\n",
    "\n",
    "- **TENURE**: Tenure of credit card service for user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of our data yields that we have lots of outliers\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have some missing values\n",
    "data.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Before we can feed our data into a clustering algorithm, we need to preprocess them.\n",
    "\n",
    "#### Task: Imputing missing values\n",
    "\n",
    "For the sake of simplicity, we can impute the missing values as the mean value. You can either use [sklearn's SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer) or do it manually.\n",
    "\n",
    "Use the cell below to answer this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Bin numeric values\n",
    "\n",
    "To cap outlier in our distributions and to provide interpretable results, it is sometimes useful to transform our numeric features into meaningful bins.\n",
    "\n",
    "For instance, the balance column can be divided into 7 bins, so that \n",
    "- the 1st bin represents values between -inf < x <= 0\n",
    "- the 2nd bin represents values between 0 < x <= 500\n",
    "- the 3rd bin represents values between 500 < x <= 1000\n",
    "- the 4th bin represents values between 1000 < x <= 3000\n",
    "- the 5th bin represents values between 3000 < x <= 5000\n",
    "- the 6th bin represents values between 5000 < x <= 10000\n",
    "- the 7th bin represents values between 10000 < x <= inf\n",
    "\n",
    "To do this for all our features, we will define a function that returns a pandas Series with the corresponding bin numbers for all values in a column of our dataframe. To illustrate the basic functionality, we can have a look at the example above. Assuming a balance of 256, the corresponding bin number will be 1 if we denote the first bin as 0. To make our function as flexible as possible it accepts a pandas Series that contains all the values to be binned and the corresponding binning thresholds as an input.\n",
    "\n",
    "To get started, you can have a look at the [pandas.cut()](https://pandas.pydata.org/docs/reference/api/pandas.cut.html) function. It provides some examples of how we can leverage this function for binning.\n",
    "\n",
    "Use the cell below to define the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_binning(series: pd.Series, thresholds: List[Union[int, float]]) -> pd.Series:\n",
    "    \n",
    "    # fill this function with your code\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first batch of column transformations\n",
    "thresholds = [-np.inf, 0, 500, 1000, 3000, 5000, 10000, np.inf]\n",
    "\n",
    "for column in ['BALANCE', 'PURCHASES', 'ONEOFF_PURCHASES', 'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS']:    \n",
    "    data[column] = apply_binning(series=data[column], thresholds=thresholds)\n",
    "\n",
    "## second batch of column transformations\n",
    "thresholds = [-np.inf, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, np.inf]\n",
    "\n",
    "for column in ['BALANCE_FREQUENCY', 'PURCHASES_FREQUENCY', 'ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY', 'CASH_ADVANCE_FREQUENCY', 'PRC_FULL_PAYMENT']:\n",
    "    data[column] = apply_binning(series=data[column], thresholds=thresholds)\n",
    "    \n",
    "## third batch of column transformations\n",
    "thresholds = [-np.inf, 0, 5, 10, 15, 20, 30, 50, 100, np.inf]\n",
    "\n",
    "for column in ['PURCHASES_TRX', 'CASH_ADVANCE_TRX']:\n",
    "    data[column] = apply_binning(series=data[column], thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop customer id since it is no longer needed \n",
    "data.drop(['CUST_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Feature Scaling\n",
    "\n",
    "Since we will be using KMeans later on, we need to scale our input data so that each feature contributes equally to the distance measure.\n",
    "\n",
    "Use the cell below to answer this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "In this notebook section, we apply the [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) clustering in two steps:\n",
    "\n",
    "1. First, we will determine the \"optimal\" number of clusters for KMeans. \n",
    "2. Once we have found this number, we will reapply the KMeans algorithm on the dataset. \n",
    "\n",
    "#### Task: Determining the number of clusters\n",
    "\n",
    "Use the elbow criterium to determine the \"optimal\" number of clusters. To do so, define a range of possible clusters and save the resulting sum of the squared distances in a list. Afterwards, you can plot the number of clusters versus the sum of squared distances, which will help you to determine the \"optimal\" number of clusters.\n",
    "\n",
    "Use the cells below to answer this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Clustering on \"optimal\" number of clusters\n",
    "\n",
    "Use the plot from above, to infer the \"optimal\" number of clusters. Use the cell below to answer this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your own labels for each data point obtained from the previous step and add it to the dataframe\n",
    "# the variable 'labels' should be supplied by you in the previous step\n",
    "clusters=pd.concat([data, pd.DataFrame({'cluster':labels})], axis=1)\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of clusters\n",
    "\n",
    "Now we can start interpreteting the clusters. For this purpose, we visualize all features with respect to the found clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in clusters:\n",
    "    grid= sns.FacetGrid(clusters, col='cluster')\n",
    "    grid.map(plt.hist, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Describe the clusters you have found in your own words. \n",
    "Use this cell for your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of clusters\n",
    "\n",
    "Now we have derived meaningful clusters from the credit card user behaviour. To further inspect our results, we will visualize the clusters. \n",
    "\n",
    "#### Task: Visualize clusters\n",
    "Currently, our feature space has more than 2 dimensions. This makes it difficult to plot our results. Hence, we need to transform our feature space into a 2D projection. In case of PCA, we simply set the number of components to 2 and transform our dataset. Afterwards, we can visualize the results. To get started with PCA, you can have a look at [sklearn's documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). To visualize the results, you can use [matplotlib](https://matplotlib.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84a58b191d90449da742b35711cf6b98468f8c1fd3c50a4e0cf298c30481a5f6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
