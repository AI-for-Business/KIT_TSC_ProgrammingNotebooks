{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfe8a55",
   "metadata": {},
   "source": [
    "# Business Data Analytics - Exercise Deep Learning\n",
    "\n",
    "In this notebook, we will apply transfer learning on the [CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset. First, we will extract bottleneck features from the pretrained model and then, build our own model on top. The pretrained neural network we will work with is the [Inception-V3](https://arxiv.org/abs/1512.00567v3), but the general idea of this approach can be applied to any other pretrained neural network. The more similar the training data of the pretrained model to the training data of the task at hand, the better features can we extract from the pretrained model. In our case, the Inception-V3 model was trained on the [ImageNet](https://de.wikipedia.org/wiki/ImageNet), which is fairly similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ca7ae",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c24955",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning and deep learning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7009f2",
   "metadata": {},
   "source": [
    "### Load and inspect the data\n",
    "\n",
    "We will first load the data and, to make our lifes easier, limit the dataset size so that training our own neural network becomes feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e57578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit dataset size if you want to see quick results\n",
    "x_train, y_train, x_test, y_test = x_train[:2500], y_train[:2500], x_test[:1000], y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect final shapes\n",
    "print('x_train shape:\\t', x_train.shape)\n",
    "print('x_test shape:\\t', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image for each class\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82dac7",
   "metadata": {},
   "source": [
    "#### Task: Plot an image of each class\n",
    "\n",
    "Fill out this function to plot an image of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efde565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_of_each_class():\n",
    "\n",
    "    # your code goes here\n",
    "    \n",
    "plot_image_of_each_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4eb04",
   "metadata": {},
   "source": [
    "### Extract features from pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eea6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# it is recommended to use an image shape greater than (75, 75)\n",
    "# we exclude the top layers so that we access the feature layers directly\n",
    "model = InceptionV3(weights='imagenet', include_top=False, input_shape=(139, 139, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we have seen earlier, the input shape of our images are not in the required shape. hence, we need to upscale them. \n",
    "# as a last step, we need to apply the same preprocessing steps that the images have undergone before they were fed \n",
    "# into the inception model for training\n",
    "def preprocess_raw_image(x: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    # resize images and transform to array\n",
    "    x_resized = np.array([np.array(Image.fromarray(x[i]).resize((139, 139))) for i in range(0, len(x))]).astype('float32')\n",
    "    \n",
    "    # further process data according to requirements of inceptionv3\n",
    "    x_inception = preprocess_input(x_resized)\n",
    "    \n",
    "    return x_inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7062902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process data for feature extraction\n",
    "x_train = preprocess_raw_image(x_train)\n",
    "x_test = preprocess_raw_image(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for shape\n",
    "assert x_train.shape[1:] == (139, 139, 3), 'shape values of training data are not in the required form'\n",
    "assert x_test.shape[1:] == (139, 139, 3), 'shape values of test data are not in the required form'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b195479",
   "metadata": {},
   "source": [
    "#### Task: Extract features from preprocessed images\n",
    "\n",
    "Fill out the function to obtain the features from our pretrained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottle_neck_features(x: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    # your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract bottleneck features\n",
    "# this might take a while\n",
    "features_train = get_bottle_neck_features(x_train)\n",
    "features_test = get_bottle_neck_features(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode features\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa14c2",
   "metadata": {},
   "source": [
    "### Train own neural network\n",
    "\n",
    "Now it is time to define and train our very first neural network.\n",
    "\n",
    "#### Task: Build a simple sequential neural network\n",
    "\n",
    "As an inspiration, you can have a look at the following architecture:\n",
    "\n",
    "<img src=\"cnn.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf55fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "def simple_model(image_shape):\n",
    "    \n",
    "    # your code goes here\n",
    "\n",
    "simple_nn = simple_model(image_shape=features_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f63f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect model architecture\n",
    "print(simple_nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model and choose optimizer, loss function and evaluation metric\n",
    "simple_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables\n",
    "batch_size = 32  # the size the batch size, the more updates during an epoch\n",
    "epochs = 10  # repeat n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "history = simple_nn.fit(features_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e78cc",
   "metadata": {},
   "source": [
    "#### Task: Evaluate the learning progess of the model by plotting its loss \n",
    "\n",
    "You can use the history variable from above to get the loss and accuracy values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5253f1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b0b01c7",
   "metadata": {},
   "source": [
    "#### Task: Evaluate your model by calculating the accuracy and confusion matrix\n",
    "\n",
    "Now it is time to test your model on the test data. Use the accuracy metric to get an overall picture of your model and the confusion matrix to dive deeper into your analysis. To plot the confusion matrix, checkout seaborn for a [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) that helps to visialize the predictions of our model. The confusion matrix itself and the accuracy can calculated with the help of [sklearn's metric functions](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b032edd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb38ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
